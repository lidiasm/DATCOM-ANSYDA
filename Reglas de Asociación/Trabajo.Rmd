---
title: "Minería de Datos: Aprendizaje no Supervisado"
subtitle: "Trabajo de Reglas de Asociación"
author: "Lidia Sánchez Mérida"
output: pdf_document
urlcolor: blue
---

# Introducción al dataset

El dataset que se ha utilizado en este trabajo de Reglas de Asociación es conocido por el nombre de [*Food Preferences*](https://www.kaggle.com/vijayashreer/food-preferences). Se trata de un conjunto de datos que representa una encuesta realizada en 2019 cuyo objetivo consiste en conocer las **preferencias culinarias en diferentes restaurantes**. A partir de esta información se pretende obtener un conjunto de dependencias y asociaciones que permitan descubrir los posibles **factores que influyen al visitar un restaurante**.
En primer lugar creamos un nuevo objeto en el que almacenar la información para comenzar a analizar sus principales características. Como podemos apreciar en los siguientes resultados, este dataset dispone de un total de **288 registros y 8 variables**, de las cuales todas son nominales a excepción de `Age` que es numérica. Adicionalmente, podemos observar que **no existen valores perdidos** por lo que cada registro tiene un valor para cada variable.

```{r}
# Cargamos el dataset del fichero
food.df <- read.csv("Food_Preference.csv")
# Dimensiones del dataset
dim(food.df)
# Tipos de variables
str(food.df)
# Número de datos perdidos
sum(is.na(food.df))
```
A continuación presentamos el resumen estadístico del dataset, en el que podemos visualizar las frecuencias de las categorías y las medidas estadísticas propias de las variables numéricas. En primer lugar destacamos que la **variable `Participant_ID` no parece proporcionar información útil** puesto que se trata de un identificador único para cada participante, por lo que no será considerada en la extracción de reglas. Ocurre una situación similar con la variable `Timestamp` ya que se encuentra muy desagregada. Sin embargo, los **intervalos horarios pueden ser de utilidad** si intentamos codificarlos en función del momento del día en el que se produce la visita al restaurante. 

Por otro lado, si observamos la variable que representa el género de los entrevistados se identifican tres tipos de valores: desconocido, masculino y femenino. La existencia del primer género puede indicar que **existen valores perdidos** codificados de un modo en el que la función **`is.na` no es capaz de identificar**, como es el caso de los espacios en blanco. Por lo tanto, será necesario aplicar un preprocesamiento en esta columna con el objetivo de reemplazar los cuatro valores perdidos. No obstante, al ser una cantidad mínima, podemos determinar que participan un número razonáblemente equitativo de mujeres y hombres, por lo que esta encuesta parece **no estar sesgada por el género**. No ocurre lo mismo con las preferencias alimenticias, las cuales se encuentran a favor de la comida traicional y el zumo fresco. También existe una amplia variedad de nacionalidades asociadas a los entrevistados, además de sus respectivos rangos de edad. Según los cuartiles de la variable `Age` podemos observar que la **mayoría de entrevistados son jóvenes** de hasta 36 años, por lo que esta encuesta puede estar sesgada por la edad de los participantes.

```{r}
# Resumen estadístico del dataset
summary(food.df)
```
## Objetivos del trabajo

A partir del análisis estadístico mostrado anteriormente, se pretende estudiar las siguientes suposiciones acerca de la relaciones existentes entre los diferentes ítems.

1. ¿Existe algún tipo de patrón alimenticio dependiendo del momento del día? Considerando tanto el tipo de comida, bebida y la inclusión de postre.
2. ¿Existen preferencias alimenticias en función de la edad, género o nacionalidad? Es decir, ¿existe algún grupo más propenso a pedir un determinado tipo de comida y/o bebida?
3. ¿Qué relaciones existen entre los diferentes tipos de comidas y bebidas? ¿Cuáles son las combinaciones más y menos comunes en la encuesta?
4. ¿Influye el tipo de comida y/o bebida elegidos para posteriormente pedir postre? 
5. ¿Existe una tendencia a pedir postre en función del momento de la comida, el género o la edad?

# Preprocesamiento de datos

En esta sección procedemos a realizar diversas transformaciones para preparar los datos con los que comenzar la extracción de reglas. El objetivo consiste en seleccionar y procesar únicamente aquellas variables que aporten información útil al problema. Para no perder el dataset original se genera un nuevo objeto que almacena el conjunto de datos preprocesado.

## Selección de variables

En este primer paso se pretende eliminar aquellas variables que no sean de utilidad para el estudio de dependencias y propiedades de los ítems. Para este dataset, únicamente **eliminamos la variable `Participant_ID`**. 

```{r message=FALSE, warning=FALSE}
# Cargamos la librería que permite el uso de pipelines
require(tidyverse)
library(tidyverse)
# Nuevo dataset sin la variable `Participant_ID`
food.prep.df <- food.df %>% select(-Participant_ID)
# Variables del nuevo dataset
colnames(food.prep.df)
```

## Discretización de variables

Existen dos variables que se deben discretizar para ser consideradas en la extracción de reglas. Para **`Timestamp`** se proponen los siguientes intervalos horarios que se corresponden con los **momentos tradicionales del día** que se conocen actualmente:

* 00 AM - 05 AM: *dawn*.
* 06 AM - 12 PM: *morning*.
* 13 PM - 18 PM: *afternoon*.
* 19 PM - 12 AM: *night*.

```{r}
# Convertimos la columna en objetos de tiempo considerando el formato AM/PM
timestamp_objs <- as.POSIXct(food.df$Timestamp, format="%Y/%m/%d %I:%M:%S %p")
# Extraemos únicamente la hora como números
timestamp_hours <- as.numeric(format(timestamp_objs, "%H"))
# Codificamos la variable `Timestamp` según los intervalos anteriores
timestamp_intervals <- 
    ifelse(timestamp_hours >=0 & timestamp_hours <= 5, 'Dawn', 
    ifelse(timestamp_hours >= 6 & timestamp_hours <= 12, 'Morning',
    ifelse(timestamp_hours >= 13 & timestamp_hours <= 18, 'Afternoon',
    ifelse(timestamp_hours >= 19, 'Night', 'LABEL NOT FOUND'))))
timestamp_intervals
# Reemplazamos los valores de la variable `Timestamp` por los codificados
# como factores
food.prep.df$Timestamp <- as.factor(timestamp_intervals)
```

Mientras que para la variable **`Age`** se presentan los siguientes rangos de valores y sus correspondientes etiquetas representando los **diferentes grupos sociales** a los que puede pertenecer una persona según su edad:

* 8 - 16 años: *infant*.
* 17 - 30 años: *young*.
* 31 - 65: *adult*.
* \> 66: *elderly*.

```{r}
# Codificamos la variable `Age` según los intervalos anteriores
age_intervals <- 
    ifelse(food.df$Age >= 8 & food.df$Age <= 16, 'Infant', 
    ifelse(food.df$Age >= 17 & food.df$Age <= 30, 'Young', 
    ifelse(food.df$Age >= 31 & food.df$Age <= 65, 'Adult', 
    ifelse(food.df$Age >= 66, 'Elderly', 'LABEL NOT FOUND'))))
age_intervals
# Reemplazamos los valores de la variable `Age` por los codificados 
# como factores
food.prep.df$Age <- as.factor(age_intervals)
```

## Normalización de categorías

Tal y como hemos podido observar en el resumen estadístico anterior, la variable `Nationality` dispone de una gran cantidad de valores. Visualizando sus categorías me he podido percatar de que existen algunas **nacionalidades codificadas de diversas formas** y, por tanto, son identificadas erróneamente como diferentes. A continuación se muestra un listado de los valores nominales de esta variable. Un caso representativo de este inconveniente es el relativo al país Malasia, que es codificado como *Malaysian*, *Malaysia *, *Malaysia*, *MALAYSIAN* o *MY*. Como consecuencia, es necesario aplicar un preprocesamiento manual para normalizar la codificación de cada nacionalidad disponible. Para ello vamos a utilizar el estándar [ISO 3166 Alpha-2](https://www.iso.org/iso-3166-country-codes.html) que etiqueta a cada país por una abreviatura compuesta de dos letras. Así aplicaremos el siguiente etiquetado:

* Algerian: *DZ*.
* Canada: *CA*.
* China: *CN*
* Indian: *IN*.
* Indonesia, Indonesain, Indonosian, Indonesian : *ID*.
* Japan: *JP*.
* Korean: *KR*.
* Malaysia, Malaysia , Malaysian, MALAYSIAN, MY: *MY*.
* Maldivian, Maldivian : *MV*.
* Mauritian: *MR*.
* Muslim: *MA*.
* Nigerian: *NG*.
* Pakistan, Pakistani, Pakistani : *PK*. 
* Seychellois: *SC*.
* Tanzanian: *TZ*.
* Yemen: *YE*.

```{r}
# Cargamos la librería que nos permite operar con strings
require(stringi)
library(stringi)
# Lista de nacionalidades únicas ordenadas alfabéticamente
nationalities <- str_sort(stri_unique(food.df$Nationality))
nationalities
# Codificamos la variable `Nationality` con las etiquetas anteriores
encoded_nats <- ifelse(grepl('Algerian', food.df$Nationality), 'DZ', 
                ifelse(grepl('Canad', food.df$Nationality), 'CA',
                ifelse(grepl('China', food.df$Nationality), 'CN',
                ifelse(grepl('India', food.df$Nationality), 'IN', 
                ifelse(grepl('Indones', food.df$Nationality), 'ID',
                ifelse(grepl('Japan', food.df$Nationality), 'JP',
                ifelse(grepl('Korean', food.df$Nationality), 'KR',
                ifelse(grepl('Malay', food.df$Nationality), 'MY',
                ifelse(grepl('MY', food.df$Nationality), 'MY',
                ifelse(grepl('MALAYSIAN', food.df$Nationality), 'MY',
                ifelse(grepl('Maldivian', food.df$Nationality), 'MV',
                ifelse(grepl('Mauritian', food.df$Nationality), 'MR',
                ifelse(grepl('Muslim', food.df$Nationality), 'MA',
                ifelse(grepl('Nigerian', food.df$Nationality), 'NG',
                ifelse(grepl('Pakistan', food.df$Nationality), 'PK',
                ifelse(grepl('Seychellois', food.df$Nationality), 'SC',
                ifelse(grepl('Tanzanian', food.df$Nationality), 'TZ',
                ifelse(grepl('Yemen', food.df$Nationality), 'YE', 
                'LABEL NOT FOUND'))))))))))))))))))
encoded_nats
# Reemplazamos los valores de la variable `Nationality` por los codificados
# como factores
food.prep.df$Nationality <- as.factor(encoded_nats)
```

## Valores perdidos

Finalmente en esta sección de preprocesamiento se procede a tratar los valores perdidos codificados como espacios en blanco que han sido encontrados en la columna `Gender` durante el análisis del dataset. En primer lugar vamos a **convertirlos a valores nulos** simbolizándolos con la denominación característica `NA`. Una vez hemos identificado los cuatro entrevistados de los que no se conoce su género, los mostramos por pantalla para conocer el resto de atributos. Como podemos apreciar se trata de cuatro personas jóvenes de nacionalidades india y árabe cuyas visitas se han producido por la tarde y de madrugada. Al ser un número mínimo de registros con valores nulos y para no introducir datos sintéticos, vamos a **eliminar estas encuestas con valores perdidos** antes de comenzar la extracción de reglas.

```{r}
# Codificamos las celdas vacías como valores nulos 
food.prep.df$Gender[food.prep.df$Gender == ""] <- NA
# Suma de valores perdidos en la columna `Gender`
sum(is.na(food.prep.df$Gender))
# Registros con valores perdidos en la columna `Gender`
food.prep.df[rowSums(is.na(food.prep.df)) > 0,]
# Eliminamos los registros con valores perdidos en la columna `Gender`
food.prep.df <- drop_na(food.prep.df)
dim(food.prep.df)
```

# Extracción de Reglas de Asociación

Tras preprocesar el dataset *Food Preferences* a continuación se prepara el conjunto de datos convirtiéndolo en un conjunto de transacciones previo a la aplicación de los algoritmos. Al disponer de una **estructura de datos tabular** su correspondiente interpretación determina que los ítems serán representados por parejas (columna, valor), mientras que las transacciones son los registros asociados a cada una de las encuestas realizadas. Como podemos visualizar en el resumen de la base de datos transaccional, existen un total de **284 transacciones y 34 ítems**, de entre los cuales también se presenta una lista con los **ítems más frecuentes**. Estos se corresponden con las categorías predominantes para cada una de las siete variables incluidas en el dataset, de modo que podemos obtener las siguientes conclusiones:

1. Existe una considerable cantidad de encuestados que han acudido a restaurantes en el **intervalo de tarde**, tomando **zumo fresco** como principal bebida, mientras que el tipo de **comida más frecuente es la tradicional**.

2. La mayoría de los entrevistados son de **nacionalidad india y género femenino**.

Adicionalmente podemos observar que **todas las transacciones disponen de 7 ítems**, lo que puede indicar que se han utilizado todas las variables consideradas en los ítemsets generados.

```{r}
# Cargamos las librerías que permiten trabajar con RAs
library(arules)
library(arulesViz)
# Convertimos el dataset a un conjunto de transacciones
food.prep.trs <- as(food.prep.df, "transactions")
summary(food.prep.trs)
```
## Items frecuentes

En el siguiente gráfico se representan los 20 **ítems más frecuentes** ordenados de mayor a menor. Como era de esperar, los cinco primeros se corresponden con los anteriores visualizados en el resumen de las transacciones, mientras que el sexto hace referencia al intervalo de edad predominante. De los restantes podemos observar los siguientes aspectos:

1. Existe una mayor representación de **encuestados indecisos al pedir postre** puesto que la frecuencia de este ítem es superior a las otras dos opciones. Parece lógico pensar que solicitar un tercer plato no suele decidirse de antemano y que depende de diversos factores, como qué platos principales se solicitan.

2. Tras la mayoría de jóvenes se encuentran el resto de entrevistados en el intervalo de **adultos**, siendo prácticamente mínimo los encuestados que pertenecen al rango de edad menor e inexistente al asociado con los más mayores.

3. El momento del día en el que existe una mayor afluencia de entrevistados es el **intervalo de tarde** de 13 PM a 18 PM. **Su frecuencia es considerablemente alta** con respecto a los restantes rangos, los cuales son más cercanos entre sí, por lo que existe prácticamente el mismo número de encuestados que han visitado restaurantes por la mañana, de noche y de madrugada. Este hecho nos indica que existe en las encuestas realizadas existe una clara preferencia por visitar restaurantes a la hora del medio día o tarde.

4. Finalmente podemos apreciar que entre los 20 ítems más frecuentes **apenas aparecen algunas nacionalidades** de las que se encuentran disponibles en el dataset. Como se ha acentuado anteriormente, la mayoría de los encuestados son de nacionalidad india, mientras que al final del gráfico podemos apreciar que algunos ítems involucran a entrevistados procedentes de Malasia, Indonesia y Pakistán.

```{r}
# Representación de los 20 ítems más frecuentes
itemFrequencyPlot(food.prep.trs, topN=20, cex.names=0.8)
```

## Itemsets frecuentes, maximales y cerrados

Una vez conocemos las parejas (atributo, valor) más comunes de la base de datos transaccional, continuamos con la extracción de los **itemsets frecuentes**. Para ello utilizaremos el algoritmo `apriori` con un **soporte mínimo de 0.1** con el objetivo de obtener aquellos que cubren una **mayor y menor proporción de los datos**. Como resultado obtenemos un total de 305 itemsets frecuentes de diferentes longitudes. Si ordenamos los resultados en orden decreciente obtenemos prácticamente la **misma información anterior** al combinar los ítems más frecuentes.

```{r}
# Obtenemos los ítemsets frecuentes
food.prep.frec <- apriori(food.prep.trs, 
                          parameter=list(support=0.1, target="frequent"))
# Ordenamos los ítemsets frecuentes por sus soportes en orden decreciente
inspect(head(sort(food.prep.frec, by="support")))
```

En el siguiente gráfico que representa la frecuencia de itemsets frecuentes con respecto a sus longitudes, podemos apreciar que la mayoría dispone de entre 3 y 4 ítems, siendo prácticamente mínimos aquellos con una longitud mínima y máxima. Esto nos puede indicar que la mayoría de itemsets **solo incluyen la mitad de las variables** disponibles, aproximadamente, para cubrir los diferentes casos que existen en este dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets frecuentes
barplot(table(size(food.prep.frec)), main="Itemsets frecuentes", col="lightgreen",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```
Para intentar reducir el número de itemsets frecuentes (305) procedemos a imponer una restricción adicional para obtener únicamente aquellos cuyos superconjuntos inmediatos son frecuentes: los **itemsets cerrados**. Como podemos apreciar, hemos conseguido un número menor de itemsets que en el caso anterior aunque siguen siendo demasiados. De hecho, si los ordenamos por su soporte en orden decreciente, podemos observar que los seis primeros **son los mismos itemsets frecuentes mostrados anteriormente**.

```{r}
# Obtenemos los itemsets cerrados
food.prep.closed <- food.prep.frec[is.closed(food.prep.frec)]
# Número de itemsets frecuentes
length(food.prep.closed)
# Ordenamos los ítemsets cerrados por sus soportes en orden decreciente
inspect(head(sort(food.prep.closed, by="support")))
```
Es tan mínima la diferencia entre los itemsets frecuentes y cerrados que se han obtenido de este dataset, que en el siguiente gráfico donde se representan las frecuencias de sus longitudes es prácticamente idéntico al anterior. Por lo tanto, entre la composición de los **itemsets frecuentes y cerrados apenas se pueden apreciar diferencias** para este dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets cerrados
barplot(table(size(food.prep.closed)), main="Itemsets cerrados", col="lightblue",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```
Continuamos reduciendo el número de itemsets calculando a continuación el último conjunto más restrictivo: los **itemsets maximales**. A diferencia de los dos casos anteriores, el número de itemsets generado es prácticamente cuatro veces menor. Adicionalmente podemos apreciar que existen dos aspectos destacables de este nuevo conjunto. Por un lado **sus soportes son mínimos**, por lo que la cobertura que realizan de los datos es particularmente escasa. Mientras que, además, la **longitud de los ítems maximales es superior** a los cerrados y frecuentes, por lo que relacionan una mayor cantidad de atributos y valores. Si observamos su composición podemos apreciar que en la mayoría aparecen características tales como el momento del día, la nacionalidad, el género y el tipo de menú solicitado.

```{r}
# Obtenemos los itemsets maximales
food.prep.max <- food.prep.frec[is.maximal(food.prep.frec)]
# Número de itemsets frecuentes
length(food.prep.max)
# Ordenamos los ítemsets maximales por sus soportes en orden decreciente
inspect(head(sort(food.prep.max, by="support")))
```
En el siguiente diagrama de barras podemos apreciar un **aumento de la longitud de los itemsets maximales**, como hemos apuntado anteriormente, siendo los más predominantes aquellos compuestos por entre 4 y 5 variables. Esto nos puede indicar que la reducción de la cantidad de itemsets tiene como consecuencia el **aumento del número de variables que intervienen** en la explicación de las diferentes combinaciones que pueden surgir dentro del dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets maximales
barplot(table(size(food.prep.max)), main="Itemsets maximales", col="salmon",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```

Para concluir este subapartado a continuación se representa el resumen del número de itemsets frecuentes, cerrados y maximales que se han obtenido para este problema particular. Tal y como hemos comentado anteriormente, el número de itemsets frecuentes y cerrados es muy similar, siendo además muy parecidas las combinaciones de ítems de las que se componen. Ambos se distinguen considerablemente del último grupo de itemsets maximales, cuyo número es más reducido a costa de aumentar la longitud y complejidad. Finalmente, podemos concluir que probablmente como consecuencia de la combinación de un mayor número de variables, sus correspondientes soportes son considerablemente menores puesto que representan situaciones menos frecuentes. 

```{r}
# Gráfico que representa el resumen del número de itemsets generados
barplot(c(Frecuentes=length(food.prep.frec), Cerrados=length(food.prep.closed), 
        Maximales=length(food.prep.max)), main="Resumen de itemsets generados",
        ylab="Frecuencia", xlab="Itemsets",
        col=c("lightgreen", "lightblue", "salmon"))
```

## Algoritmo Apriori

El primer algoritmo que procedemos a aplicar es **Apriori** para la extracción de reglas con un **soporte mínimo de 0.1 y una confianza mínima de 0.8**. Adicionalmente imponemos la restricción de que cada regla disponga al menos de componentes, el antecedente y el consecuente. Como podemos observar en el resumen mostrado a continuación, esta técnica ha logrado generar un total de **338 reglas con longitudes de entre 2 y 6 ítems**, aunque la mayoría de ellas contienen 4 ítems concretamente. En relación a las medidas de calidad que se calculan por defecto, podemos observar que la **mayoría de reglas disponen de un soporte mínimo**, puesto que apenas existe diferencia entre el Q1 y Q3. Este hecho nos indica que existe una concentración de reglas que **representan dependencias y relaciones entre ítems poco frecuentes**, lo cual puede ser interesante para un estudio posterior. Por otro lado podemos observar que el primer y tercer cuartil de la medida de interés o *lift* son mayores que uno, lo que puede reflejar la existencia de **dependencias positivas** entre los diferentes ítems.

```{r}
# Extracción de reglas con el algoritmo Apriori con soporte mínimo de 0.1, 
# confianza mínima de 0.8 y longitud mínima de 2.
food.apriori.rules <- apriori(food.prep.trs, 
                        parameter=list(support=0.1, confidence=0.8, minlen=2))
# Resumen de las reglas obtenidas
summary(food.apriori.rules)
```

A continuación procedemos a aplicar un preprocesamiento de modo que se eliminen tanto las **reglas iguales como las redundantes**. En el primer caso se trata de reglas cuyos antecedentes son iguales o subconjuntos de los antecedentes de otras reglas, mientras que en la segunda situación son reglas cuyos antecedentes y consecuentes son iguales aunque intercambiados de posición. Tras aplicar sendos filtros, podemos observar que **el conjunto de reglas se reduce drásticamente** hasta únicamente disponer de 66. Como consecuencia podemos apreciar el aumento del número de reglas con una menor longitud, mientras que el **número de reglas de mayor tamaño ha disminuido considerablemente**. Si observamos el resumen estadístico que se muestra a continuación, podemos apreciar que los niveles de **soporte y confianza no han varíado** prácticamente nada, mientras que la métrica de calidad *lift* ha aumentado ligeramente sus valores tanto en el mínimo como en los cuartiles. Esto nos puede indicar que este nuevo conjunto de reglas más reducido dispone de la misma cobertura y confianza que el conjunto original por lo que el preprocesamiento efectuado parece no haber afectado a su calidad.

```{r}
# Ordenamos las reglas según la confianza
food.apriori.rules <- sort(food.apriori.rules, by="confidence")
# Obtenemos los itemsets que han generado las reglas
food.apriori.itemsets <- generatingItemsets(food.apriori.rules)
food.apriori.equal.rules <- which(duplicated(food.apriori.itemsets))
# Descartamos aquellas reglas que sean iguales 
# o muy similares en el antecedente
food.apriori.rules <- food.apriori.rules[-food.apriori.equal.rules]
# Obtenemos las reglas reglas que son redundantes
food.apriori.redundant <- is.redundant(x=food.apriori.rules, measure = "confidence")
# Descartamos las reglas redundantes
food.apriori.rules <- food.apriori.rules[!food.apriori.redundant] 
# Resumen de las reglas finales
summary(food.apriori.rules)
```
En el siguiente gráfico representamos este nuevo conjunto de reglas reducido, en el que podemos apreciar que existen dos reglas situadas en la esquina inferior izquierda con un **alto valor de *lift*, una confianza alrededor del 80-85% aunque con un bajo soporte**. Este grupo de asociaciones pueden representar situaciones que suelen ocurrir con una razonable seguridad pero con una baja frecuencia. Por lo tanto, se trata de dependencias fuertes y extrañas que pueden proporcionar información muy útil con la que analizar las preferencias culinarias del público en los restaurantes.

```{r}
# Representamos gráficamente las reglas podadas visualizando sus soportes,
# confianzas y lift
plot(food.apriori.rules, jitter=0)
```
A continuación se muestran las dos reglas destacadas anteriormente para conocer su composición y analizarlas en profundidad. En primer lugar, mientras que sus soportes son valores considerablemente bajos, sus confianzas y *lift* son bastante más altos, lo que nos indica que son **reglas poco frecuentes pero con cierta seguridad** de que aparezcan los consecuentes si suceden los antecedentes. La primera de ellas apuesta por la hipótesis de que si una persona adulta visita un restaurante y no conoce a ciencia cierta si pedirá postre, es probable que se trate de una mujer. Esta regla puede ser útil en tanto en cuanto demuestra **patrones alimenticios dependientes del género** ya que nos indica que las mujeres pueden ser más indecisas en relación a tomar postre tras la comida. En el caso de la segunda regla podemos observar que el **patrón se encuentra asociado al momento del día puesto** que su hipótesis predice que la comida oriental es más solicitada durante el intervalo de tarde. De nuevo, esta segunda regla parece muy interesante puesto que puede identificar el tipo de menús que prefieren los comensales dependiendo del tipo de comida que vayan a consumir, en este caso parece tratarse de un almuerzo.

```{r}
# Subconjunto de reglas
food.apriori.rules.subset <- subset(food.apriori.rules, 
                      subset=lift >= 1.1 & support < 0.3 & confidence <= 0.85)
# Mostramos las reglas obtenidas
inspect(food.apriori.rules.subset)
```

Con el objetivo de intentar obtener más asociaciones informativas acerca de las relaciones existentes entre los ítems, vamos a añadir dos medidas de calidad adicionales al soporte, la confianza y *lift*. La primera de ellas se denomina ***confirmedConfidence*** y representa la regla con la confianza de la misma pero negando el consecuente, mientras que la segunda se conoce como ***leastContradiction***, que calcula el nivel de contradicción de la regla en base a las transacciones de la base de datos. Cuanto más elevados sean ambos valores, mejor será la calidad de la regla. Si observamos el nuevo conjunto podemos notar que es **más numeroso que el anterior y que los soportes de las reglas han aumentado considerablemente**, lo que nos indica que este conjunto de reglas parece aportar información más común. Por contra, los valores de la confianza y el *lift* han disminuido, lo que puede representar una disminución de las ocurrencias de los consecuentes y si aparecen sus correspondientes antecedentes.

Si observamos la composición de las reglas, podemos apreciar que la mayoría de antecedentes y consecuentes coinciden, por lo que un **análisis en grupo** podría ser más idóneo que un estudio individualizado. Por una parte parece haber un **patrón alimenticio entre el tipo de comida y la bebida**: la comida tradicional con el zumo fresco. Mientras que por otro lado, parece que este tipo de menú es el **más popular entre los entrevistados de origen indio**. Por lo tanto, a mi parecer, este conjunto podría **reducirse a únicamente las reglas 2 y 4** que son las que contienen estas deducciones. Si bien es interesante este tipo de información para seguir conociendo el comportamiento de los comensales, como habíamos comentado anteriormente, estas conclusiones se pueden deducir del análisis exploratorio realizado anteriormente.

```{r}
# Calculamos la confianza confirmada
quality(food.apriori.rules)$confirmedConfidence <- 
    interestMeasure(food.apriori.rules, measure = "confirmedConfidence")
# Calculamos la mínima contradicción
quality(food.apriori.rules)$leastContradiction <- 
    interestMeasure(food.apriori.rules, measure = "leastContradiction")
# Subconjunto de reglas
inspect(subset(food.apriori.rules,
               confirmedConfidence > 0.7 & leastContradiction > 0.7))
```

### Conclusiones

Unificando la información extraída anteriormente y agrupando las diferentes reglas generadas con el algoritmo Apriori y que han parecido ser más relevantes, a continuación realizamos un resumen de las hipótesis obtenidas y el estado de los objetivos de este proyecto.

1. En primer lugar parece existir un patrón alimenticio dependiente tanto de la composición del menú como del momento del día en el que se consume. En el primer caso parece existir una **preferencia por la combinación de comida tradicional y zumo fresco**, mientras que la hipótesis del segundo afirma que el público es **más propenso a consumir un menú oriental durante el almuerzo**.

2. También hemos podido observar que los **comensales de origen indio disponen de cierta preferencia por el menú tradicional** comentado anteriormente, considerando que tanto el tipo de comida, bebida y la nacionalidad son valores mayoritarios en este dataset por lo que su representación es predominante sobre las restantes categorías.

3. Finalmente parece que se define un nuevo **patrón que relaciona la edad, el género y la decisión sobre tomar postre**. Este afirma que si se trata de una persona adulta y no sabe con seguridad si solicitará un tercer plato, es probable que sea una mujer. De ser así, el dueño de un restaurante podría estar interesado en investigar sobre los motivos de su indecisión y sobre las posibles soluciones a aplicar para animar a este colectivo al consumo del plato final.

## Algoritmo FP-growth

En este apartado se pretende experimentar con el algoritmo **FP-growth** para intentar obtener conjuntos de reglas que nos ayuden a identificar nuevas relaciones y dependencias entre los ítems disponibles.  Para ello haremos uso del paquete `rCBA` y de la función `fpgrowth`, a la que se le proporciona la base de datos transaccional, un soporte y confianza mínimos, además de la longitud mínima de las reglas y la **columna objetivo que se establece como consecuente**. Para comparar sendos algoritmos, se aplicarán los mismos valores anteriores para los umbrales de calidad pero no el preprocesamiento de borrado de reglas iguales y redundantes, ya que este algoritmo produce conjuntos de reglas con mayor diferencias entre sí.

Comenzamos estudiando el momento del día estableciendo **`Timestamp` en el consecuente** con el que obtenemos un conjunto con una única regla. Se trata de la misma regla que apareció anteriormente con el algoritmo Apriori que indicaba la preferencia por la **comida oriental en el intervalo de tarde**. Por lo tanto, podemos descartarla ya que conocemos esta información.

```{r}
# Cargamos la librería para utilizar el algoritmo FP-growth
require(rCBA)
library(rCBA)
# Obtenemos reglas cuyo consecuente sean ítems de `Timestamp`
food.fpg.timestamp.rules <- fpgrowth(food.prep.trs, support=0.1, confidence=0.8, 
                             maxLength=2, consequent="Timestamp")
# Subconjunto de reglas
inspect(food.fpg.timestamp.rules)
```
A continuación establecemos la variable **`Nationality` en el consecuente** para obtener un nuevo conjunto de reglas con el mismo algoritmo y parámetros anteriores. En este caso podemos observar que todas ellas disponen de un único antecedente, por lo que se trata de reglas sencillas y fuertes. Adicionalmente, sus soportes son ínfimos, a excepción de la última regla, aunque sus confianzas son máximas. De nuevo se trata de reglas poco frecuentes pero caracterizadas por una gran seguridad. Las tres primeras relacionan la aparición de **comensales indios a los períodos de mañana y noche**. Si recordamos la información extraída anteriormente, este tipo de público solía consumir comida tradicional mayoritariamente. Al unir estas tres primeras reglas podemos determinar que el **menú tradicional suele ser preferente durante los intervalos de mañana y noche**. 
Por otro lado, la última regla parece indicar que aproximadamente un 36% de los **entrevistados de origen indio pertenecen al intervalo de adultos** de entre 31 y 65 años. Considerando que el rango mayoritario de edad es el joven, esta información es sumamente útil puesto que lo lógico hubiese sido relacionar la nacionalidad predominante con el intervalo de edad mayoritario.

```{r}
# Obtenemos reglas cuyo consecuente sean ítems de `Nationality`
food.fpg.nationalityrules <- fpgrowth(food.prep.trs, support=0.1, confidence=0.8, 
                             maxLength=2, consequent="Nationality")
# Subconjunto de reglas
inspect(subset(food.fpg.nationalityrules, subset=lift >= 1.1 | lift <= 0.9))
```

Si situamos a la variable **`Food`como consecuente** podemos apreciar que este tercer conjunto de reglas contiene información que ya conocíamos gracias al caso anterior. Por un lado confirma el consumo de comida tradicional durante el intervalo de mañana y la madrugada, mientras que por otra parte se refuerza la teoría de que son los adultos los que consumen el menú tradicional. No obstante, la tercera regla es sumamente informativa puesto que representa un patrón importante que asocia el **no pedir postre con el consumo de comida tradicional**. Esta regla se caracteriza por disponer de un soporte más alto que las restantes y por una confianza y *lift* bastante altos como para determinar que existe una relación entre sendos ítems. Si consideramos que la comida tradicional suele ser preferible durante el intervalo de mañana entre las 6 AM y las 12 AM, puede ser lógico pensar que **durante el desayuno no se consume postre**. Sin embargo, parece que **esta tendencia también se repite para la cena**, por lo tanto puede ser un punto interesante para realizar un análisis de los motivos que llevan a un comensal a no pedir el tercer plato y actuar en consecuencia para fomentar este consumo.

```{r}
# Obtenemos reglas cuyo consecuente sean ítems de `Food`
food.fpg.food.rules <- fpgrowth(food.prep.trs, support=0.1, confidence=0.8, 
                             maxLength=2, consequent="Food")
# Subconjunto de reglas
inspect(subset(food.fpg.food.rules, subset=lift >= 1.1 | lift <= 0.9))
```

Finalmente generamos el último conjunto de reglas mediante el algoritmo FP-growth estableciendo la variable **`Juice` como consecuente**. Tras filtrar según la confianza y la medida de calidad *lift* como en los casos anteriores, podemos apreciar la existencia de dos reglas cuya información ya es conocida. La primera afirma que durante el **intervalo de mañana se consume jugo fresco**. Esta preferencia la conocíamos puesto que entre las 6 AM y las 12 AM se consume el menú tradicional que va acompañado de jugo fresco. Mientras que la segunda regla indica que un comensal **no pide postre si solicita jugo fresco**. De nuevo esta información es conocida puesto que anteriormente hemos comprobado cómo los entrevistados rechazan pedir el tercer plato si consumen el menú tradicional con el jugo fresco. Por lo tanto, **ambas reglas parecen ser despreciables**.

```{r}
# Obtenemos reglas cuyo consecuente sean ítems de `Juice`
food.fpg.juice.rules <- fpgrowth(food.prep.trs, support=0.1, confidence=0.8, 
                             maxLength=2, consequent="Juice")
# Subconjunto de reglas
inspect(subset(food.fpg.juice.rules, subset=lift >= 1.1 | lift <= 0.9))
```
### Conclusiones

En este subapartado, de nuevo, se exponen las conclusiones que se pueden obtener al añadir la información obtenida mediante la extracción de reglas con el algoritmo FP-growth a las hipótesis observadas con el primer algoritmo Apriori. 

1. En primer lugar podemos determinar que la comida tradicional con zumo fresco se suele servir durante los intervalos de mañana y noche, mientras que la comida oriental está más solicitada durante el intervalo de tarde. Por lo tanto ya disponemos de un posible **patrón que relaciona el tipo de menú con el momento del día** en el que se prefiere consumir.

2. Adicionalmente parece que si se opta por el **menú tradicional no se consume postre**. Como hemos comentado anteriormente, si se trata de desayunos es lógico pensar que los comensales no solicitan este tercer plato. Sin embargo, al aparecer también durante la cena puede suponer un caso de **estudio específico para fomentar su consumo** durante esta comida. Si recordamos una de las hipótesis obtenidas con el primer algoritmo, parece ser que las **mujeres adultas son las que se encuentran más indecisas** en relación al tercer plato. Por lo tanto, podemos intuir que es probable que sea **el género opuesto, el masculino, el que rechace con determinación el consumo de postre**.

## Inclusión de ítems negativos

Tras realizar diversas extracciones de reglas mediante la aplicación de los algoritmos Apriori y FP-growth sobre el dataset preprocesado, a continuación presentamos una reproducción de los análisis anteriores con la **inclusión de ítems negativos**. El proceso para su generación es similar a la binarización de una variable, en el que se crea una nueva columna por cada posible valor y se indica la existencia de cada uno mediante números binarios. Una de las variables que más se prestan al significado de los ítems negativos es la columna **`Food`, que representa si una persona escoge un menú o el contrario**. Mientras que otra de las columnas más propensas a esta experimentación podría ser **`Dessert` puesto que contiene las tres posibles decisiones** en relación al consumo de postre tras la comida principal.

Una vez disponemos de un nuevo dataset con las dos columnas anteriores transformadas, lo convertimos en una base de datos transaccional con la que comenzar a analizar sus ítems. Como podemos visualizar tanto en el resumen como en el gráfico de los 20 ítems más frecuentes, este conjunto de transacciones es prácticamente idéntico al anterior, a excepción de las nuevas columnas *dummies*.

```{r}
# Cargamos la librería que nos permite transformar una columna en dummy
require(fastDummies)
library(fastDummies)
# Creamos un nuevo dataset preprocesado con las columnas dummificadas
food.prep.dumm.df <- dummy_cols(food.prep.df, c('Food', 'Dessert'), 
                                remove_selected_columns=TRUE)
# Cambiamos el nombre de las columnas a otros más sencillos
colnames(food.prep.dumm.df) <- c('Timestamp', 'Gender', 'Nationality', 
       'Age', 'Juice', 'TraditionalFood', 'WesternFood', 'DessertMaybe', 
       'DessertNo', 'DessertYes')
# Convertimos los valores binarios a lógicos
food.prep.dumm.df[6:ncol(food.prep.dumm.df)] <- 
        sapply(c(6:ncol(food.prep.dumm.df)), 
        function(x) as.logical(food.prep.dumm.df[, x]))
# Transformamos el nuevo dataset a transacciones
food.prep.dumm.trs <- as(food.prep.dumm.df, "transactions")
summary(food.prep.dumm.trs)
# Representación de los 20 ítems más frecuentes
itemFrequencyPlot(food.prep.dumm.trs, topN=20, cex.names=0.8)
```
A continuación generamos el primer conjunto de reglas incluyendo ítems negativos mediante el algoritmo Apriori con los mismos parámetros y preprocesamiento aplicados hasta el momento. Como era de esperar, **si el conjunto de transacciones es prácticamente igual al primero sin incluir los ítems negativos, el conjunto de reglas obtenido también es considerablemente similar**. De hecho, si observamos el gráfico que representa las 66 reglas resultantes tras el preprocesamiento, podemos apreciar que las reglas destacables son las mismas que las analizadas anteriormente.

```{r}
# Extracción de reglas con el algoritmo Apriori con soporte mínimo de 0.1, 
# confianza mínima de 0.8 y longitud mínima de 2.
food.apriori.neg.rules <- apriori(food.prep.dumm.trs, 
                        parameter=list(support=0.1, confidence=0.8, minlen=2))
# Ordenamos las reglas según la confianza
food.apriori.neg.rules <- sort(food.apriori.neg.rules, by="confidence")
# Obtenemos los itemsets que han generado las reglas
food.apriori.neg.itemsets <- generatingItemsets(food.apriori.neg.rules)
food.apriori.equal.neg.rules <- which(duplicated(food.apriori.neg.itemsets))
# Descartamos aquellas reglas que sean iguales 
# o muy similares en el antecedente
food.apriori.neg.rules <- food.apriori.neg.rules[-food.apriori.equal.neg.rules]
# Obtenemos las reglas reglas que son redundantes
food.apriori.neg.redundant <- is.redundant(x=food.apriori.neg.rules, measure = "confidence")
# Descartamos las reglas redundantes
food.apriori.neg.rules <- food.apriori.neg.rules[!food.apriori.neg.redundant] 
# Resumen de las reglas finales
summary(food.apriori.neg.rules)
# Representamos gráficamente las reglas podadas visualizando sus soportes,
# confianzas y lift
plot(food.apriori.neg.rules, jitter=0)
```

Tras experimentar con diferentes medidas de calidad para este nuevo conjunto de reglas con ítems negativos,a la métrica con la que se han obtenido reglas más interesantes se conoce como el **índice de implicación**. Se trata de una variante de la similitud de Lerman cuya fórmula contiene el consecuente negado. Cuanto más alejado se encuentre de 0, mayor dependencia existe entre el antecedente y el consecuente. 

Tal y como se observa en los resultados, **la primera regla** ya ha aparecido en análisis anteriores por lo que **puede ser descartada**. Sin embargo la segunda afirma que si un comensal pertenece al intervalo de jóvenes, tiene un 85% de seguridad de solicitar zumo fresco. Si recordamos que este tipo de bebida está asociada a la comida tradicional, podemos intuir que los entrevistados **más jóvenes también consumen este tipo de menú**, y por ende, son aplicables todas las conclusiones extraídas anteriormente acerca del consumo de postre y del momento del día. Adicionalmente, la tercera regla parece indicar que el género masculino también consume este tipo de bebida con un 85% de confianza y un 1.52 del índice de implicación, además de su alto soporte. Esto nos puede indicar que **no existe diferencias entre los menús que consumen ambos géneros**.

Finalmente las cuarta regla parece contradecir la teoría anterior de que al consumir comida tradicional y zumo fresco no era de esperar que el comensal solicitase postre. A diferencia de la regla que considera el hecho de no tomar postre, esta cuarta regla dispone de un **soporte más alto aunque una menor confianza**. Estas medidas indican que existen un mayor número de encuestados que sí se solicitan el tercer plato aunque también simboliza una **relación más débil entre el antecedente y el consecuente**. Una situación similar ocurre con la última regla que también rompe la teoría de que los comensales de origen indio tampoco solicitaban postre tras consumir el menú tradicional con zumo fresco. La única excepción podía ser el caso de las mujeres adultas que parecían estar más indecisas. El hecho de que el consumo de postre pueda ser más predominante en este dataset concreto no significa que esta tendencia se cumpla para el resto de comensales no entrevistados. Por lo tanto, a mi parecer, seguiría considerando más en serio la situación en la cual el **tercer plato no es solicitado puesto que la probabilidad de acierto es bastante mayor** que la que proponen estas dos últimas reglas.

```{r}
# Calculamos una variación de la similitud de Lerman
quality(food.apriori.neg.rules)$implicationIndex <- 
    interestMeasure(food.apriori.neg.rules, measure = "implicationIndex")
# Subconjunto de reglas
inspect(subset(food.apriori.neg.rules, subset=implicationIndex > 0.5))
```
## Otros algoritmos

# Conclusiones finales
