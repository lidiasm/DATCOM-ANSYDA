---
title: "Minería de Datos: Aprendizaje no Supervisado"
subtitle: "Trabajo de Reglas de Asociación"
author: "Lidia Sánchez Mérida"
output: pdf_document
urlcolor: blue
---

# Introducción al dataset

El dataset que se ha utilizado en este trabajo de Reglas de Asociación es conocido por el nombre de [*Food Preferences*](https://www.kaggle.com/vijayashreer/food-preferences). Se trata de un conjunto de datos que representa una encuesta realizada en 2019 cuyo objetivo consiste en conocer las **preferencias culinarias en diferentes restaurantes**. A partir de esta información se pretende obtener un conjunto de dependencias y asociaciones que permitan descubrir los posibles **factores que influyen al visitar un restaurante**.
En primer lugar creamos un nuevo objeto en el que almacenar la información para comenzar a analizar sus principales características. Como podemos apreciar en los siguientes resultados, este dataset dispone de un total de **288 registros y 8 variables**, de las cuales todas son nominales a excepción de `Age` que es numérica. Adicionalmente, podemos observar que **no existen valores perdidos** por lo que cada registro tiene un valor para cada variable.

```{r}
# Cargamos el dataset del fichero
food.df <- read.csv("Food_Preference.csv")
# Dimensiones del dataset
dim(food.df)
# Tipos de variables
str(food.df)
# Número de datos perdidos
sum(is.na(food.df))
```
A continuación presentamos el resumen estadístico del dataset, en el que podemos visualizar las frecuencias de las categorías y las medidas estadísticas propias de las variables numéricas. En primer lugar destacamos que la **variable `Participant_ID` no parece proporcionar información útil** puesto que se trata de un identificador único para cada participante, por lo que no será considerada en la extracción de reglas. Ocurre una situación similar con la variable `Timestamp` ya que se encuentra muy desagregada. Sin embargo, los **intervalos horarios pueden ser de utilidad** si intentamos codificarlos en función del momento del día en el que se produce la visita al restaurante. 

Por otro lado, si observamos la variable que representa el género de los entrevistados se identifican tres tipos de valores: desconocido, masculino y femenino. La existencia del primer género puede indicar que **existen valores perdidos** codificados de un modo en el que la función **`is.na` no es capaz de identificar**, como es el caso de los espacios en blanco. Por lo tanto, será necesario aplicar un preprocesamiento en esta columna con el objetivo de reemplazar los cuatro valores perdidos. No obstante, al ser una cantidad mínima, podemos determinar que participan un número razonáblemente equitativo de mujeres y hombres, por lo que esta encuesta parece **no estar sesgada por el género**. No ocurre lo mismo con las preferencias alimenticias, las cuales se encuentran a favor de la comida traicional y el zumo fresco. También existe una amplia variedad de nacionalidades asociadas a los entrevistados, además de sus respectivos rangos de edad. Según los cuartiles de la variable `Age` podemos observar que la **mayoría de entrevistados son jóvenes** de hasta 36 años, por lo que esta encuesta puede estar sesgada por la edad de los participantes.

```{r}
# Resumen estadístico del dataset
summary(food.df)
```
## Objetivos del trabajo

A partir del análisis estadístico mostrado anteriormente, se pretende estudiar las siguientes suposiciones acerca de la relaciones existentes entre los diferentes ítems.

1. ¿Existe algún tipo de patrón alimenticio dependiendo del momento del día? Considerando tanto el tipo de comida, bebida y la inclusión de postre.
2. ¿Existen preferencias alimenticias en función de la edad, género o nacionalidad? Es decir, ¿existe algún grupo más propenso a pedir un determinado tipo de comida y/o bebida?
3. ¿Qué relaciones existen entre los diferentes tipos de comidas y bebidas? ¿Cuáles son las combinaciones más y menos comunes en la encuesta?
4. ¿Influye el tipo de comida y/o bebida elegidos para posteriormente pedir postre? 
5. ¿Existe una tendencia a pedir postre en función del momento de la comida, el género o la edad?

# Preprocesamiento de datos

En esta sección procedemos a realizar diversas transformaciones para preparar los datos con los que comenzar la extracción de reglas. El objetivo consiste en seleccionar y procesar únicamente aquellas variables que aporten información útil al problema. Para no perder el dataset original se genera un nuevo objeto que almacena el conjunto de datos preprocesado.

## Selección de variables

En este primer paso se pretende eliminar aquellas variables que no sean de utilidad para el estudio de dependencias y propiedades de los ítems. Para este dataset, únicamente **eliminamos la variable `Participant_ID`**. 

```{r message=FALSE, warning=FALSE}
# Cargamos la librería que permite el uso de pipelines
require(tidyverse)
library(tidyverse)
# Nuevo dataset sin la variable `Participant_ID`
food.prep.df <- food.df %>% select(-Participant_ID)
# Variables del nuevo dataset
colnames(food.prep.df)
```

## Discretización de variables

Existen dos variables que se deben discretizar para ser consideradas en la extracción de reglas. Para **`Timestamp`** se proponen los siguientes intervalos horarios que se corresponden con los **momentos tradicionales del día** que se conocen actualmente:

* 00 AM - 05 AM: *dawn*.
* 06 AM - 12 PM: *morning*.
* 13 PM - 18 PM: *afternoon*.
* 19 PM - 12 AM: *night*.

```{r}
# Convertimos la columna en objetos de tiempo considerando el formato AM/PM
timestamp_objs <- as.POSIXct(food.df$Timestamp, format="%Y/%m/%d %I:%M:%S %p")
# Extraemos únicamente la hora como números
timestamp_hours <- as.numeric(format(timestamp_objs, "%H"))
# Codificamos la variable `Timestamp` según los intervalos anteriores
timestamp_intervals <- ifelse(timestamp_hours >=0 & timestamp_hours <= 5, 'Dawn', 
    ifelse(timestamp_hours >= 6 & timestamp_hours <= 12, 'Morning',
    ifelse(timestamp_hours >= 13 & timestamp_hours <= 18, 'Afternoon',
    ifelse(timestamp_hours >= 19, 'Night', 'LABEL NOT FOUND'))))
timestamp_intervals
# Reemplazamos los valores de la variable `Timestamp` por los codificados
# como factores
food.prep.df$Timestamp <- as.factor(timestamp_intervals)
```

Mientras que para la variable **`Age`** se presentan los siguientes rangos de valores y sus correspondientes etiquetas representando los **diferentes grupos sociales** a los que puede pertenecer una persona según su edad:

* 8 - 16 años: *infant*.
* 17 - 30 años: *young*.
* 31 - 65: *adult*.
* \> 66: *elderly*.

```{r}
# Codificamos la variable `Age` según los intervalos anteriores
age_intervals <- ifelse(food.df$Age >= 8 & food.df$Age <= 16, 'Infant', 
    ifelse(food.df$Age >= 17 & food.df$Age <= 30, 'Young', 
    ifelse(food.df$Age >= 31 & food.df$Age <= 65, 'Adult', 
    ifelse(food.df$Age >= 66, 'Elderly', 'LABEL NOT FOUND'))))
age_intervals
# Reemplazamos los valores de la variable `Age` por los codificados 
# como factores
food.prep.df$Age <- as.factor(age_intervals)
```

## Normalización de categorías

Tal y como hemos podido observar en el resumen estadístico anterior, la variable `Nationality` dispone de una gran cantidad de valores. Visualizando sus categorías me he podido percatar de que existen algunas **nacionalidades codificadas de diversas formas** y, por tanto, son identificadas erróneamente como diferentes. A continuación se muestra un listado de los valores nominales de esta variable. Un caso representativo de este inconveniente es el relativo al país Malasia, que es codificado como *Malaysian*, *Malaysia *, *Malaysia*, *MALAYSIAN* o *MY*. Como consecuencia, es necesario aplicar un preprocesamiento manual para normalizar la codificación de cada nacionalidad disponible. Para ello vamos a utilizar el estándar [ISO 3166 Alpha-2](https://www.iso.org/iso-3166-country-codes.html) que etiqueta a cada país por una abreviatura compuesta de dos letras. Así aplicaremos el siguiente etiquetado:

* Algerian: *DZ*.
* Canada: *CA*.
* China: *CN*
* Indian: *IN*.
* Indonesia, Indonesain, Indonosian, Indonesian : *ID*.
* Japan: *JP*.
* Korean: *KR*.
* Malaysia, Malaysia , Malaysian, MALAYSIAN, MY: *MY*.
* Maldivian, Maldivian : *MV*.
* Mauritian: *MR*.
* Muslim: *MA*.
* Nigerian: *NG*.
* Pakistan, Pakistani, Pakistani : *PK*. 
* Seychellois: *SC*.
* Tanzanian: *TZ*.
* Yemen: *YE*.

```{r}
# Cargamos la librería que nos permite operar con strings
require(stringi)
library(stringi)
# Lista de nacionalidades únicas ordenadas alfabéticamente
nationalities <- str_sort(stri_unique(food.df$Nationality))
nationalities
# Codificamos la variable `Nationality` con las etiquetas anteriores
encoded_nats <- ifelse(grepl('Algerian', food.df$Nationality), 'DZ', 
                ifelse(grepl('Canad', food.df$Nationality), 'CA',
                ifelse(grepl('China', food.df$Nationality), 'CN',
                ifelse(grepl('India', food.df$Nationality), 'IN', 
                ifelse(grepl('Indones', food.df$Nationality), 'ID',
                ifelse(grepl('Japan', food.df$Nationality), 'JP',
                ifelse(grepl('Korean', food.df$Nationality), 'KR',
                ifelse(grepl('Malay', food.df$Nationality), 'MY',
                ifelse(grepl('MY', food.df$Nationality), 'MY',
                ifelse(grepl('MALAYSIAN', food.df$Nationality), 'MY',
                ifelse(grepl('Maldivian', food.df$Nationality), 'MV',
                ifelse(grepl('Mauritian', food.df$Nationality), 'MR',
                ifelse(grepl('Muslim', food.df$Nationality), 'MA',
                ifelse(grepl('Nigerian', food.df$Nationality), 'NG',
                ifelse(grepl('Pakistan', food.df$Nationality), 'PK',
                ifelse(grepl('Seychellois', food.df$Nationality), 'SC',
                ifelse(grepl('Tanzanian', food.df$Nationality), 'TZ',
                ifelse(grepl('Yemen', food.df$Nationality), 'YE', 
                'LABEL NOT FOUND'))))))))))))))))))
encoded_nats
# Reemplazamos los valores de la variable `Nationality` por los codificados
# como factores
food.prep.df$Nationality <- as.factor(encoded_nats)
```

## Valores perdidos

Finalmente en esta sección de preprocesamiento se procede a tratar los valores perdidos codificados como espacios en blanco que han sido encontrados en la columna `Gender` durante el análisis del dataset. En primer lugar vamos a **convertirlos a valores nulos** simbolizándolos con la denominación característica `NA`. Una vez hemos identificado los cuatro entrevistados de los que no se conoce su género, los mostramos por pantalla para conocer el resto de atributos. Como podemos apreciar se trata de cuatro personas jóvenes de nacionalidades india y árabe cuyas visitas se han producido por la tarde y de madrugada. Al ser un número mínimo de registros con valores nulos y para no introducir datos sintéticos, vamos a **eliminar estas encuestas con valores perdidos** antes de comenzar la extracción de reglas.

```{r}
# Codificamos las celdas vacías como valores nulos 
food.prep.df$Gender[food.prep.df$Gender == ""] <- NA
# Suma de valores perdidos en la columna `Gender`
sum(is.na(food.prep.df$Gender))
# Registros con valores perdidos en la columna `Gender`
food.prep.df[rowSums(is.na(food.prep.df)) > 0,]
# Eliminamos los registros con valores perdidos en la columna `Gender`
food.prep.df <- drop_na(food.prep.df)
dim(food.prep.df)
```

# Extracción de Reglas de Asociación

Tras preprocesar el dataset *Food Preferences* a continuación se prepara el conjunto de datos convirtiéndolo en un conjunto de transacciones previo a la aplicación de los algoritmos. Al disponer de una **estructura de datos tabular** su correspondiente interpretación determina que los ítems serán representados por parejas (columna, valor), mientras que las transacciones son los registros asociados a cada una de las encuestas realizadas. Como podemos visualizar en el resumen de la base de datos transaccional, existen un total de **284 transacciones y 34 ítems**, de entre los cuales también se presenta una lista con los **ítems más frecuentes**. Estos se corresponden con las categorías predominantes para cada una de las siete variables incluidas en el dataset, de modo que podemos obtener las siguientes conclusiones:

1. Existe una considerable cantidad de encuestados que han acudido a restaurantes en el **intervalo de tarde**, tomando **zumo fresco** como principal bebida, mientras que el tipo de **comida más frecuente es la tradicional**.

2. La mayoría de los entrevistados son de **nacionalidad india y género femenino**.

Adicionalmente podemos observar que **todas las transacciones disponen de 7 ítems**, lo que puede indicar que se han utilizado todas las variables consideradas en los ítemsets generados.

```{r}
# Cargamos las librerías que permiten trabajar con RAs
library(arules)
library(arulesViz)
# Convertimos el dataset a un conjunto de transacciones
food.prep.trs <- as(food.prep.df, "transactions")
summary(food.prep.trs)
```
## Items frecuentes

En el siguiente gráfico se representan los 20 **ítems más frecuentes** ordenados de mayor a menor. Como era de esperar, los cinco primeros se corresponden con los anteriores visualizados en el resumen de las transacciones, mientras que el sexto hace referencia al intervalo de edad predominante. De los restantes podemos observar los siguientes aspectos:

1. Existe una mayor representación de **encuestados indecisos al pedir postre** puesto que la frecuencia de este ítem es superior a las otras dos opciones. Parece lógico pensar que solicitar un tercer plato no suele decidirse de antemano y que depende de diversos factores, como qué platos principales se solicitan.

2. Tras la mayoría de jóvenes se encuentran el resto de entrevistados en el intervalo de **adultos**, siendo prácticamente mínimo los encuestados que pertenecen al rango de edad menor e inexistente al asociado con los más mayores.

3. El momento del día en el que existe una mayor afluencia de entrevistados es el **intervalo de tarde** de 13 PM a 18 PM. **Su frecuencia es considerablemente alta** con respecto a los restantes rangos, los cuales son más cercanos entre sí, por lo que existe prácticamente el mismo número de encuestados que han visitado restaurantes por la mañana, de noche y de madrugada. Este hecho nos indica que existe en las encuestas realizadas existe una clara preferencia por visitar restaurantes a la hora del medio día o tarde.

4. Finalmente podemos apreciar que entre los 20 ítems más frecuentes **apenas aparecen algunas nacionalidades** de las que se encuentran disponibles en el dataset. Como se ha acentuado anteriormente, la mayoría de los encuestados son de nacionalidad india, mientras que al final del gráfico podemos apreciar que algunos ítems involucran a entrevistados procedentes de Malasia, Indonesia y Pakistán.

```{r}
# Representación de los 20 ítems más frecuentes
itemFrequencyPlot(food.prep.trs, topN=20, cex.names=0.8)
```

## Itemsets frecuentes, maximales y cerrados

Una vez conocemos las parejas (atributo, valor) más comunes de la base de datos transaccional, continuamos con la extracción de los **itemsets frecuentes**. Para ello utilizaremos el algoritmo `apriori` con un **soporte mínimo de 0.1** con el objetivo de obtener aquellos que cubren una **mayor y menor proporción de los datos**. Como resultado obtenemos un total de 305 itemsets frecuentes de diferentes longitudes. Si ordenamos los resultados en orden decreciente obtenemos prácticamente la **misma información anterior** al combinar los ítems más frecuentes.

```{r}
# Obtenemos los ítemsets frecuentes
food.prep.frec <- apriori(food.prep.trs, parameter=list(support=0.1, target="frequent"))
# Ordenamos los ítemsets frecuentes por sus soportes en orden decreciente
inspect(head(sort(food.prep.frec, by="support")))
```

En el siguiente gráfico que representa la frecuencia de itemsets frecuentes con respecto a sus longitudes, podemos apreciar que la mayoría dispone de entre 3 y 4 ítems, siendo prácticamente mínimos aquellos con una longitud mínima y máxima. Esto nos puede indicar que la mayoría de itemsets **solo incluyen la mitad de las variables** disponibles, aproximadamente, para cubrir los diferentes casos que existen en este dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets frecuentes
barplot(table(size(food.prep.frec)), main="Itemsets frecuentes", col="lightgreen",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```
Para intentar reducir el número de itemsets frecuentes (305) procedemos a imponer una restricción adicional para obtener únicamente aquellos cuyos superconjuntos inmediatos son frecuentes: los **itemsets cerrados**. Como podemos apreciar, hemos conseguido un número menor de itemsets que en el caso anterior aunque siguen siendo demasiados. De hecho, si los ordenamos por su soporte en orden decreciente, podemos observar que los seis primeros **son los mismos itemsets frecuentes mostrados anteriormente**.

```{r}
# Obtenemos los itemsets cerrados
food.prep.closed <- food.prep.frec[is.closed(food.prep.frec)]
# Número de itemsets frecuentes
length(food.prep.closed)
# Ordenamos los ítemsets cerrados por sus soportes en orden decreciente
inspect(head(sort(food.prep.closed, by="support")))
```
Es tan mínima la diferencia entre los itemsets frecuentes y cerrados que se han obtenido de este dataset, que en el siguiente gráfico donde se representan las frecuencias de sus longitudes es prácticamente idéntico al anterior. Por lo tanto, entre la composición de los **itemsets frecuentes y cerrados apenas se pueden apreciar diferencias** para este dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets cerrados
barplot(table(size(food.prep.closed)), main="Itemsets cerrados", col="lightblue",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```
Continuamos reduciendo el número de itemsets calculando a continuación el último conjunto más restrictivo: los **itemsets maximales**. A diferencia de los dos casos anteriores, el número de itemsets generado es prácticamente cuatro veces menor. Adicionalmente podemos apreciar que existen dos aspectos destacables de este nuevo conjunto. Por un lado **sus soportes son mínimos**, por lo que la cobertura que realizan de los datos es particularmente escasa. Mientras que, además, la **longitud de los ítems maximales es superior** a los cerrados y frecuentes, por lo que relacionan una mayor cantidad de atributos y valores. Si observamos su composición podemos apreciar que en la mayoría aparecen características tales como el momento del día, la nacionalidad, el género y el tipo de menú solicitado.

```{r}
# Obtenemos los itemsets maximales
food.prep.max <- food.prep.frec[is.maximal(food.prep.frec)]
# Número de itemsets frecuentes
length(food.prep.max)
# Ordenamos los ítemsets maximales por sus soportes en orden decreciente
inspect(head(sort(food.prep.max, by="support")))
```
En el siguiente diagrama de barras podemos apreciar un **aumento de la longitud de los itemsets maximales**, como hemos apuntado anteriormente, siendo los más predominantes aquellos compuestos por entre 4 y 5 variables. Esto nos puede indicar que la reducción de la cantidad de itemsets tiene como consecuencia el **aumento del número de variables que intervienen** en la explicación de las diferentes combinaciones que pueden surgir dentro del dataset.

```{r}
# Gráfico que representa la frecuencia de las diferentes longitudes de los
# itemsets maximales
barplot(table(size(food.prep.max)), main="Itemsets maximales", col="salmon",
        xlab="Longitud de los itemsets", ylab="Número de itemsets")
```

Para concluir este subapartado a continuación se representa el resumen del número de itemsets frecuentes, cerrados y maximales que se han obtenido para este problema particular. Tal y como hemos comentado anteriormente, el número de itemsets frecuentes y cerrados es muy similar, siendo además muy parecidas las combinaciones de ítems de las que se componen. Ambos se distinguen considerablemente del último grupo de itemsets maximales, cuyo número es más reducido a costa de aumentar la longitud y complejidad. Finalmente, podemos concluir que probablmente como consecuencia de la combinación de un mayor número de variables, sus correspondientes soportes son considerablemente menores puesto que representan situaciones menos frecuentes. 

```{r}
# Gráfico que representa el resumen del número de itemsets generados
barplot(c(Frecuentes=length(food.prep.frec), Cerrados=length(food.prep.closed), 
        Maximales=length(food.prep.max)), main="Resumen de itemsets generados",
        ylab="Frecuencia", xlab="Itemsets",
        col=c("lightgreen", "lightblue", "salmon"))
```

## Algoritmo Apriori

El primer algoritmo que procedemos a aplicar es **Apriori** para la extracción de reglas con un **soporte mínimo de 0.1 y una confianza mínima de 0.8**. Adicionalmente imponemos la restricción de que cada regla disponga al menos de componentes, el antecedente y el consecuente. Como podemos observar en el resumen mostrado a continuación, esta técnica ha logrado generar un total de **338 reglas con longitudes de entre 2 y 6 ítems**, aunque la mayoría de ellas contienen 4 ítems concretamente. En relación a las medidas de calidad que se calculan por defecto, podemos observar que la **mayoría de reglas disponen de un soporte mínimo**, puesto que apenas existe diferencia entre el Q1 y Q3. Este hecho nos indica que existe una concentración de reglas que **representan dependencias y relaciones entre ítems poco frecuentes**, lo cual puede ser interesante para un estudio posterior. Por otro lado podemos observar que el primer y tercer cuartil de la medida de interés o *lift* son mayores que uno, lo que puede reflejar la existencia de **dependencias positivas** entre los diferentes ítems.

```{r}
# Extracción de reglas con el algoritmo Apriori con soporte mínimo de 0.1, 
# confianza mínima de 0.8 y longitud mínima de 2.
food.apriori.rules <- apriori(food.prep.trs, 
                        parameter=list(support=0.1, confidence=0.8, minlen=2))
# Resumen de las reglas obtenidas
summary(food.apriori.rules)
```
Si ordenamos las reglas según la confianza y podamos las que sean redundantes en base a esta medida de calidad, podemos apreciar que **el conjunto de reglas se reduce drásticamente** hasta únicamente disponer de 90. De este modo hemos eliminado todas aquellas que aportan prácticamente la misma información a la representación de dependencias y asociaciones entre los ítems. Como consecuencia también se puede observar un mayor **equilibrio entre el número de reglas que pertenencen a las diferentes longitudes**. A diferencia del caso anterior, en este conjunto de reglas podadas no existe una única longitud predominante, si no que la mayoría dispone de entre 2 y 4 ítems.

```{r}
# Ordenamos las reglas extraídas según la confianza
food.apriori.sorted.rules <- sort(food.apriori.rules, by="confidence")
# Obtenemos las reglas redundantes según la confianza
food.apriori.redundant <- is.redundant(x=food.apriori.sorted.rules, 
                                       measure = "confidence")
# Podamos las reglas redundantes
food.apriori.pruned.rules <- food.apriori.sorted.rules[!food.apriori.redundant] 
# Resumen de las reglas restantes
summary(food.apriori.pruned.rules)
```
En el siguiente gráfico representamos este nuevo conjunto de reglas reducido en el que podemos apreciar que existen unas siete reglas situadas en la esquina inferior izquierda con un **alto valor de *lift*, una confianza alrededor del 80-85% aunque con un bajo soporte**. Este grupo de asociaciones pueden representar situaciones que suelen ocurrir con una razonable seguridad pero con una baja frecuencia. Por lo tanto, se trata de dependencias fuertes y extrañas que pueden proporcionar información muy útil con el objetivo de estudiar las preferencias del público en los restaurantes.

```{r}
# Representamos gráficamente las reglas podadas visualizando sus soportes,
# confianzas y lift
plot(food.apriori.pruned.rules, jitter=0)
```
A continuación obtenemos este conjunto de siete reglas particular para su estudio en profundidad. Como podemos apreciar, existen reglas de las tres longitudes mayoritarias que anteriormente se han observado con 1, 2 y 3 componentes. Las conclusiones que se pueden extraer de esete subconjunto se detallan a continuación:

1. La hipótesis de la primera regla consiste en afirmar que si la persona que visita un restaurante se encuentra en el intervalo de edad adulto, es decir entre 31 y 65 años, y no conoce a priori se pedirá postre existe un 83% de confianza de que se trate de una mujer. En mi opinión, al tratarse de un **valor tan ambiguo no creo que podamos considerar esta regla como interesante** puesto que uno de los antecedentes no nos indica si la persona en cuestión tomará o no postre. Una situación similar ocurre con la segunda regla al incluir el valor `maybe` en el antecedente. Además su consecuente indica que si se cumplen las condiciones del antecedente, es probable que se trate de una **persona joven**. Considerando la **representación mayoritaria** de este grupo, tampoco me parece una regla relevante.

2. Reglas 3, 4, 6 y7 aportan la misma información pero sí indican un patrón de persona y comida.
3. Regla 5 indica un patrón de comidas por momento del día.

```{r}
# Subconjunto de reglas con lift>1.2, soporte<0.3 y confianza<0.85
food.apriori.pruned.rules.subset <- subset(food.apriori.pruned.rules, 
                     subset=lift > 1.2 & support < 0.3 & confidence < 0.85)
# Longitud del subconjunto
length(food.apriori.pruned.rules.subset)
# Mostramos las reglas obtenidas
inspect(head(food.apriori.pruned.rules.subset, 7))
```

